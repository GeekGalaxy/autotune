#+TITLE: Acksin Autotune
#+AUTHOR: Acksin
#+OPTIONS: html-postamble:nil body-only: t

#+begin_quote

#+end_quote

* Introduction

Autotune the Linux to get the optimal server performance.

Acksin Autotune makes sure that your Linux servers are utilized as
efficiently as possible. It does this by tuning your Linux kernel
based on various criteria. The type of application profile, memory,
CPUs, instance type to bring out the best performance for your
machine.

* Usage

** Help
#+begin_src sh
autotune -help
#+end_src

#+RESULTS:

** List Signatures

#+begin_src sh :results output code :exports both
autotune -list
#+end_src

#+RESULTS:
#+BEGIN_SRC sh
{
  "Open": [
    "apache",
    "fs",
    "golang",
    "haproxy",
    "io",
    "memory",
    "networking",
    "nginx",
    "nodejs",
    "postgresql"
  ],
  "Pro": [
    "java",
    "ruby2"
  ],
  "Premium": [
    "cassandra",
    "raid",
    "ruby18"
  ]
}
#+END_SRC

#+RESULTS:


** Tuning

*** Show Signature

#+begin_src sh :results output code :exports both
autotune golang
#+end_src

#+RESULTS:
#+BEGIN_SRC sh
{
  "Name": "golang",
  "Description": "Configuration for high throughput Golang apps",
  "Documentation": "# Linux Optimizations for High Throughput Golang Apps\n\nGo applications have unique characteristics which require certain\nLinux kernel tuning to achieve high throughput.\n\n## Go's Utilization Profile\n\nCPU will not be a bottleneck with Golang applications. Our research\nshows that applications, even those that utilize CGO, do no see CPU be\na bottleneck. The places where performance become bottlenecks are the\nfollowing:\n\n - Garbage Collection\n - Default ulimits\n - Networking\n\n## Assumptions\n\nWe will be under the assumption that there will be one primary Go\napplication running on the machine and can have access to all of the\nresources. We also assume that we want high network throughput as the\ngoal is to have high response rate. We want to be able to handle\nmillions of requests.\n\n## GC Optimizations\n\nFor all intents and purposes we should be able to increase the GOGC to\na number based on the size of the machine. If I am using a m4.large\ninstance on Amazon I use GOGC=10000. The higher the GOGC value the\nless frequent the Garbage Collection will run. Further, since we are\noptimizing the server to be heavily utilized for a primary Golang\nservice we want to use up all the RAM available to us.\n\n## Ulimits\n\nUlimits are a security mechanism in POSIX based systems which gives\neach user a certain amount of allocation of various\nresources. However, the resource we are concerned with is file\ndescriptors. (ulimit -n) Since a file descriptor can be a file or a\nsocket we can quickly saturate how many connections an app not running\nas root can use. Further, the default open files ulimit on an Ubuntu\nServer 14.04 are ridiculously low at 1024.\n\nThe server will reach network saturation quickly if this is not dealt\nwith. Further, since we want to optimize for the single Golang\napplication we will give every user on the Linux machine unlimited\nopen files.\n\n## Networking\n\nhttps://engineering.gosquared.com/optimising-nginx-node-js-and-networking-for-heavy-workloads\n",
  "ProcFS": {
    "net.core.netdev_max_backlog": {
      "Value": "30000",
      "Description": "The number of incoming connections on the backlog queue. The\nmaximum number of packets queued on the INPUT side.\n"
    },
    "net.core.rmem_max": {
      "Value": "16777216",
      "Description": "The size of the receive buffer for all the sockets. 16MB per\nsocket.\n"
    },
    "net.core.somaxconn": {
      "Value": "16096",
      "Description": "The maximum number of queued sockets on a connection.\n"
    },
    "net.core.wmem_max": {
      "Value": "16777216",
      "Description": "The size of the buffer for all the sockets. 16MB per socket.\n"
    },
    "net.ipv4.ip_local_port_range": {
      "Value": "1024 65535",
      "Description": "On a typical machine there are around 28000 ports available to\nbe bound to. This number can get exhausted quickly if there are\nmany connections. We will increase this.\n"
    },
    "net.ipv4.tcp_fin_timeout": {
      "Value": "15",
      "Description": "Usually, the Linux kernel holds a TCP connection even after it\nis closed for around two minutes. This means that there may be a\nport exhaustion as the kernel waits to close the connections. By\nmoving the fin_timeout to 15 seconds we drastically reduce the\nlength of time the kernel is waiting for the socket to get any\nremaining packets.\n"
    },
    "net.ipv4.tcp_max_syn_backlog": {
      "Value": "20480",
      "Description": "Increase the number syn requests allowed. Sets how many\nhalf-open connections to backlog queue\n"
    },
    "net.ipv4.tcp_max_tw_buckets": {
      "Value": "400000",
      "Description": "Increase the tcp-time-wait buckets pool size to prevent simple\nDOS attacks\n"
    },
    "net.ipv4.tcp_no_metrics_save": {
      "Value": "1",
      "Description": "TCP saves various connection metrics in the route cache when the\nconnection closes so that connections established in the near\nfuture can use these to set initial conditions. Usually, this\nincreases overall performance, but may sometimes cause\nperformance degradation.\n"
    },
    "net.ipv4.tcp_rmem": {
      "Value": "4096 87380 16777216",
      "Description": "(min, default, max): The sizes of the receive buffer for the IP protocol.\n"
    },
    "net.ipv4.tcp_syn_retries": {
      "Value": "2",
      "Description": "Number of times initial SYNs for a TCP connection attempt will\nbe retransmitted for outgoing connections.\n"
    },
    "net.ipv4.tcp_synack_retries": {
      "Value": "2",
      "Description": "This setting determines the number of SYN+ACK packets sent\nbefore the kernel gives up on the connection\n"
    },
    "net.ipv4.tcp_syncookies": {
      "Value": "1",
      "Description": "Security to prevent DDoS attacks.\n\nhttp://cr.yp.to/syncookies.html\n"
    },
    "net.ipv4.tcp_wmem": {
      "Value": "4096 65536 16777216",
      "Description": "(min, default, max): The sizes of the write buffer for the IP protocol.\n"
    },
    "net.netfilter.nf_conntrack_max": {
      "Value": "200000",
      "Description": "The max is double the previous value.\n\nhttps://wiki.khnet.info/index.php/Conntrack_tuning\n"
    },
    "proc.file-max": {
      "Value": "2097152",
      "Description": "The max amount of file handlers that the Linux kernel will\nallocate. This is one part the other part is setting the\nulimits.\n"
    },
    "proc.min_free_kbytes": {
      "Value": "65536",
      "Description": "Amount of memory to keep free. Don't want to make this too high\nas Linux will spend more time trying to reclaim memory.\n"
    },
    "vm.min_free_kbytes": {
      "Value": "65536",
      "Description": "Keep 64MB or Ram available at all times so if things are not\nworking we can, at least, SSH to the system and do tasks and not\nget an out of memory error.\n"
    }
  },
  "SysFS": {
    "/sys/module/nf_conntrack/parameters/hashsize": {
      "Value": "50000"
    }
  },
  "Env": {
    "GOGC": {
      "Value": "2000",
      "Description": "Set the value of GOGC to be really high.\n\nTODO: Consider how this is being used as part of a bigger\nsetting. Based on RAM etc.\n"
    }
  },
  "Vars": {
    "nfConntrackMax": 200000
  }
}
#+END_SRC

#+RESULTS:

*** ProcFS Changes

 #+begin_src sh :results output code :exports both
 autotune sig -show=procfs golang
 #+end_src

 #+RESULTS:
 #+BEGIN_SRC sh
 null
 #+END_SRC

 #+RESULTS:

*** SysFS Changes

 #+begin_src sh :results output code :exports both
 autotune sig -show=sysfs golang
 #+end_src

 #+RESULTS:
 #+BEGIN_SRC sh
 null
 #+END_SRC

 #+RESULTS:

*** Environment Variable Changes

 #+begin_src sh :results output code :exports both
 autotune sig -show=env golang
 #+end_src

 #+RESULTS:
 #+BEGIN_SRC sh
 null
 #+END_SRC

 #+RESULTS:

* Open Signatures

#+begin_src ruby :results output drawer :exports results
  require 'json'

  sigs = JSON.parse(`./autotune -list`)

  sigs["Open"].each do |s|
    sigInfo = JSON.parse(`./autotune -deps=false #{s}`)

    puts "** #{sigInfo["Name"]}"
    puts
    puts sigInfo["Documentation"]
    puts

    ["ProcFS", "SysFS", "Env"].each do |type|
      if !!sigInfo[type]
        puts "*** #{type}"
        puts
        puts "#+ATTR_HTML: :class table"
        puts "|#{type} Key|Value|Description|"
        puts "| <10> | <8> ||" if type == "Env"
        sigInfo[type].each do |k, v|
          puts "|=#{k}=|=#{v["Value"] rescue ""}=|#{v["Description"].gsub("\n", ' ') rescue ""}|"
        end
      end
    end

    if !!sigInfo["Deps"] && !sigInfo["Deps"].empty?
      puts "*** Dependencies"
      puts
      sigInfo["Deps"].each do |k|
        puts " - [[#{k}][#{k}]]"
      end
      puts
    end
  end
#+end_src

#+RESULTS:
:RESULTS:
** apache

NewApacheConfig returns the configuration for the Apache HTTP Server.
TODO: Eventually it should be split into apache2-mpm and
apache2-fork.

*** ProcFS

#+ATTR_HTML: :class table
|ProcFS Key|Value|Description|
|=kernel.sched_autogroup_enabled=|=0=||
|=kernel.sched_migration_cost_ns=|=5000000=||
*** Dependencies

 - [[networking][networking]]

** fs



*** ProcFS

#+ATTR_HTML: :class table
|ProcFS Key|Value|Description|
|=vm.dirty_background_ratio=|=5=||
|=vm.dirty_expire_centisecs=|=1200=||
|=vm.dirty_ratio=|=80=||
** golang

# Linux Optimizations for High Throughput Golang Apps

Go applications have unique characteristics which require certain
Linux kernel tuning to achieve high throughput.

## Go's Utilization Profile

CPU will not be a bottleneck with Golang applications. Our research
shows that applications, even those that utilize CGO, do no see CPU be
a bottleneck. The places where performance become bottlenecks are the
following:

 - Garbage Collection
 - Default ulimits
 - Networking

## Assumptions

We will be under the assumption that there will be one primary Go
application running on the machine and can have access to all of the
resources. We also assume that we want high network throughput as the
goal is to have high response rate. We want to be able to handle
millions of requests.

## GC Optimizations

For all intents and purposes we should be able to increase the GOGC to
a number based on the size of the machine. If I am using a m4.large
instance on Amazon I use GOGC=10000. The higher the GOGC value the
less frequent the Garbage Collection will run. Further, since we are
optimizing the server to be heavily utilized for a primary Golang
service we want to use up all the RAM available to us.

## Ulimits

Ulimits are a security mechanism in POSIX based systems which gives
each user a certain amount of allocation of various
resources. However, the resource we are concerned with is file
descriptors. (ulimit -n) Since a file descriptor can be a file or a
socket we can quickly saturate how many connections an app not running
as root can use. Further, the default open files ulimit on an Ubuntu
Server 14.04 are ridiculously low at 1024.

The server will reach network saturation quickly if this is not dealt
with. Further, since we want to optimize for the single Golang
application we will give every user on the Linux machine unlimited
open files.

## Networking

https://engineering.gosquared.com/optimising-nginx-node-js-and-networking-for-heavy-workloads

*** Env

#+ATTR_HTML: :class table
|Env Key|Value|Description|
| <10> | <8> ||
|=GOGC=|=2000=|Set the value of GOGC to be really high.  TODO: Consider how this is being used as part of a bigger setting. Based on RAM etc. |
*** Dependencies

 - [[networking][networking]]

** haproxy



*** Dependencies

 - [[networking][networking]]

** io



*** SysFS

#+ATTR_HTML: :class table
|SysFS Key|Value|Description|
|=/sys/block/*/queue/read_ahead_kb=|=256=||
|=/sys/block/*/queue/rq_afinity=|=2=||
|=/sys/block/*/queue/scheduler=|=noop=||
** memory



*** ProcFS

#+ATTR_HTML: :class table
|ProcFS Key|Value|Description|
|=vm.swappiness=|=0=|Disable swapping and clear the file system page cache to free memory first. |
*** SysFS

#+ATTR_HTML: :class table
|SysFS Key|Value|Description|
|=/sys/kernel/mm/transparent_hugepage/enabled=|=always=|Explit huge page usage making the page size of 2 or 4 MB instead of 4kb. Should reduce CPU overhead and improve MMU page translation. |
** networking

Many of these settings were from the following places:
  - http://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux.html
  - https://rtcamp.com/tutorials/linux/sysctl-conf/
  - https://fasterdata.es.net/host-tuning/linux/
  - http://cherokee-project.com/doc/other_os_tuning.html
  - https://easyengine.io/tutorials/linux/sysctl-conf/

TODO: These setting are sort of set in stone but I feel that they
can adapt as the system is being used. We don't have to set them to
the values but we can migrate and change as we learn more about the
system and tune it appropriately.

*** ProcFS

#+ATTR_HTML: :class table
|ProcFS Key|Value|Description|
|=net.core.netdev_max_backlog=|=30000=|The number of incoming connections on the backlog queue. The maximum number of packets queued on the INPUT side. |
|=net.core.rmem_max=|=16777216=|The size of the receive buffer for all the sockets. 16MB per socket. |
|=net.core.somaxconn=|=16096=|The maximum number of queued sockets on a connection. |
|=net.core.wmem_max=|=16777216=|The size of the buffer for all the sockets. 16MB per socket. |
|=net.ipv4.ip_local_port_range=|=1024 65535=|On a typical machine there are around 28000 ports available to be bound to. This number can get exhausted quickly if there are many connections. We will increase this. |
|=net.ipv4.tcp_fin_timeout=|=15=|Usually, the Linux kernel holds a TCP connection even after it is closed for around two minutes. This means that there may be a port exhaustion as the kernel waits to close the connections. By moving the fin_timeout to 15 seconds we drastically reduce the length of time the kernel is waiting for the socket to get any remaining packets. |
|=net.ipv4.tcp_max_syn_backlog=|=20480=|Increase the number syn requests allowed. Sets how many half-open connections to backlog queue |
|=net.ipv4.tcp_max_tw_buckets=|=400000=|Increase the tcp-time-wait buckets pool size to prevent simple DOS attacks |
|=net.ipv4.tcp_no_metrics_save=|=1=|TCP saves various connection metrics in the route cache when the connection closes so that connections established in the near future can use these to set initial conditions. Usually, this increases overall performance, but may sometimes cause performance degradation. |
|=net.ipv4.tcp_rmem=|=4096 87380 16777216=|(min, default, max): The sizes of the receive buffer for the IP protocol. |
|=net.ipv4.tcp_syn_retries=|=2=|Number of times initial SYNs for a TCP connection attempt will be retransmitted for outgoing connections. |
|=net.ipv4.tcp_synack_retries=|=2=|This setting determines the number of SYN+ACK packets sent before the kernel gives up on the connection |
|=net.ipv4.tcp_syncookies=|=1=|Security to prevent DDoS attacks.  http://cr.yp.to/syncookies.html |
|=net.ipv4.tcp_wmem=|=4096 65536 16777216=|(min, default, max): The sizes of the write buffer for the IP protocol. |
|=net.netfilter.nf_conntrack_max=|={{ index .Vars "nfConntrackMax" }}=|The max is double the previous value.  https://wiki.khnet.info/index.php/Conntrack_tuning |
|=proc.file-max=|=2097152=|The max amount of file handlers that the Linux kernel will allocate. This is one part the other part is setting the ulimits. |
|=proc.min_free_kbytes=|=65536=|Amount of memory to keep free. Don't want to make this too high as Linux will spend more time trying to reclaim memory. |
|=vm.min_free_kbytes=|=65536=|Keep 64MB or Ram available at all times so if things are not working we can, at least, SSH to the system and do tasks and not get an out of memory error. |
*** SysFS

#+ATTR_HTML: :class table
|SysFS Key|Value|Description|
|=/sys/module/nf_conntrack/parameters/hashsize=|={{ divide (index .Vars "nfConntrackMax") 4 }}=||
** nginx



*** Dependencies

 - [[networking][networking]]

** nodejs



*** Dependencies

 - [[networking][networking]]

** postgresql

- http://www.postgresql.org/message-id/50E4AAB1.9040902@optionshouse.com
- http://www.postgresql.org/docs/9.1/static/kernel-resources.html

*** ProcFS

#+ATTR_HTML: :class table
|ProcFS Key|Value|Description|
|=kernel.sched_autogroup_enabled=|=0=||
|=kernel.sched_migration_cost_ns=|=5000000=||
|=kernel.shmall=|=4194304=||
|=kernel.shmmax=|=17179869184=||
:END:
